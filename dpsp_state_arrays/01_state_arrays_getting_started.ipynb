{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State array analysis for single-particle tracks\n",
    "Alec Heckert, Liza Dahal, Robert Tijan, Xavier Darzacq (2022) Recovering mixtures of fast-diffusing states from short single-particle trajectories eLife 11:e70169  \n",
    "https://doi.org/10.7554/eLife.70169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main python packages\n",
    "from glob import glob\n",
    "import os\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "\n",
    "# 3rd party packages\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib_scalebar.scalebar as sb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from saspt import StateArray, RBME\n",
    "from saspt.lik import RBMELikelihood\n",
    "import scipy.io\n",
    "\n",
    "# locally installed package\n",
    "import biteen_utilities as bu\n",
    "\n",
    "# to suppress annoying warning\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"DejaVu Sans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where is data coming from? Where is output going?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## where is data coming from?\n",
    "fits_folder = r\"T:\\MIGRATED\\Python\\biteen_notebooks_example_data\\LAM_RNAP_SMALLLABS\" # drive letter may be different on your computer\n",
    "fits_pattern = \"*_fits.mat\"\n",
    "\n",
    "masks_folder = r\"T:\\MIGRATED\\Python\\biteen_notebooks_example_data\\LAM_RNAP_SMALLLABS\"\n",
    "masks_pattern = \"*_PhaseMask.mat\"\n",
    "\n",
    "## where will output be saved\n",
    "output_folder = join(os.getcwd(), \"state_array_output\") # cwd: current working directory\n",
    "probabilities_csv_fname = \"state_array_test_output.csv\"\n",
    "figures_pdf_fname = \"state_array_test_plots.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters\n",
    "# track filtering parameters\n",
    "min_track_len = 6 # in number of localizations\n",
    "max_track_len = np.inf\n",
    "\n",
    "# state array parameters\n",
    "pixel_size_um = 0.049 # um\n",
    "frame_interval = 0.04 # seconds\n",
    "focal_depth = 0.7 # um\n",
    "diff_coefs = np.logspace(-3, 1, 100) # um^2 / s\n",
    "loc_errors = np.linspace(0, 0.1, 30) # um\n",
    "likelihood_type = RBME # imported from saspt package\n",
    "\n",
    "## plotting parameters\n",
    "cmap = mpl.cm.cool \n",
    "vmin = np.log10(diff_coefs[0])\n",
    "vmax = np.log10(diff_coefs[-1])\n",
    "lmin = -2 # tracks with D_app < 10^lmin will appear cyan\n",
    "lmax = -1 # tracks with D_app > 10^lmax will appear magenta\n",
    "\n",
    "# overall plot\n",
    "ymax_overall_plot = None\n",
    "minor_line_color = 'xkcd:grey'\n",
    "minor_line_width = 1.5\n",
    "minor_line_alpha = 0.3\n",
    "major_line_color = 'xkcd:black'\n",
    "major_line_width = 3\n",
    "\n",
    "# movie plots\n",
    "ymax_movie_plot = None\n",
    "roi_line_width = 1 \n",
    "roi_line_alpha = 0.5\n",
    "roi_line_color = 'xkcd:gray'\n",
    "marker_size = 5\n",
    "marker_alpha = 0.33\n",
    "\n",
    "# scalebar parameters\n",
    "default_scalebar_props = {\n",
    "    'dx': pixel_size_um,\n",
    "    'units': 'um',\n",
    "    'fixed_value': 2,\n",
    "    'scale_loc': 'none',\n",
    "    'location': 'lower right',\n",
    "    'frameon': False,\n",
    "    'color': 'xkcd:white'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the fits files\n",
    "fits_files = glob(join(fits_folder, fits_pattern)) \n",
    "\n",
    "# find mask files\n",
    "masks_files = glob(join(masks_folder, masks_pattern)) \n",
    "\n",
    "# check for matching number of files\n",
    "print(f\"{len(fits_files)} fits files found and {len(masks_files)} masks files found\")\n",
    "if len(fits_files) != len(masks_files):\n",
    "    print(\"Warning: there should be one masks file for every fits file\")\n",
    "\n",
    "# initiate a list to hold DataFrames containing fits data\n",
    "all_dfs = [] \n",
    "curr_max_id = 0\n",
    "\n",
    "# loop over fits files:\n",
    "for i, fits_file in enumerate(fits_files):\n",
    "\n",
    "    # read SMALL-LABS fit file and convert to pandas DataFrame\n",
    "    fits_data = bu.slfile_to_df(fits_file)\n",
    "    \n",
    "    # only consider good fits\n",
    "    fits_data = fits_data[fits_data['goodfit'] == True] \n",
    "\n",
    "    # filter tracks by number of localizations\n",
    "    fits_data = bu.filter_by_nlocs(\n",
    "        fits_data, \n",
    "        min_locs=min_track_len, \n",
    "        max_locs=max_track_len, \n",
    "        track_col='track_id'\n",
    "        )\n",
    "    \n",
    "    # provide unique movie id\n",
    "    fits_data['movie_id'] = i\n",
    "\n",
    "    # shift track_ids to be unique\n",
    "    track_ids = fits_data['track_id'].dropna().unique()\n",
    "    n_ids = len(track_ids)\n",
    "    new_ids = np.arange(n_ids) + curr_max_id\n",
    "    curr_max_id = new_ids[-1] + 1\n",
    "    fits_data['track_id_unique'] = fits_data['track_id'].replace(\n",
    "        track_ids,\n",
    "        new_ids\n",
    "    )\n",
    "\n",
    "    # build list of DataFrames\n",
    "    all_dfs.append(fits_data)\n",
    "\n",
    "# assemble into single DataFrame for passing into state array analysis\n",
    "all_fits = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# create unique roinum across movies\n",
    "all_fits['roinum_unique'] = all_fits.groupby(['movie_id', 'roinum']).ngroup() + 1\n",
    "\n",
    "# rename columns for state array analysis\n",
    "detections = all_fits.rename(columns={\n",
    "    'col': 'x',\n",
    "    'row': 'y',\n",
    "    'track_id_unique': 'trajectory'\n",
    "    })\n",
    "\n",
    "# load masks\n",
    "all_masks = [scipy.io.loadmat(masks_file)['PhaseMask'] for masks_file in masks_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State array calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "rbme_likelihood = RBMELikelihood(\n",
    "    pixel_size_um = pixel_size_um, # um\n",
    "    frame_interval = frame_interval, # seconds\n",
    "    focal_depth = focal_depth, # um\n",
    "    diff_coefs = diff_coefs, # um^2/s\n",
    "    loc_errors = loc_errors # um\n",
    "    )\n",
    "settings = dict(\n",
    "    likelihood_type = likelihood_type,\n",
    "    pixel_size_um = pixel_size_um, # um\n",
    "    frame_interval = frame_interval, # seconds\n",
    "    focal_depth = focal_depth, # um\n",
    "    progress_bar = True,\n",
    ")\n",
    "\n",
    "# run state array analysis with model\n",
    "SA = StateArray.from_detections(\n",
    "    detections[['x', 'y', 'trajectory', 'frame']], \n",
    "    **settings\n",
    "    )\n",
    "SA.likelihood = rbme_likelihood\n",
    "SA.posterior_assignment_probabilities;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary calculation, e.g. D_av for each trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find estimated probabilities for each individual\n",
    "track_probabilities = SA.posterior_assignment_probabilities.sum(axis=1)\n",
    "\n",
    "# find expectation value of diffusion coefficient for each track\n",
    "Dav_track = (track_probabilities * SA.diff_coefs[:,None]).sum(axis=0)\n",
    "detections_sa = SA.trajectories.detections # distinct from detections because analysis does not necessarily use all localizations\n",
    "detections_sa['D_av'] = Dav_track[detections_sa['trajectory']]\n",
    "\n",
    "# find overall probability\n",
    "overall_probability = SA.posterior_occs.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge SA detections with input detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fits['track_id_SA'] = np.nan\n",
    "all_fits.loc[detections_sa['detect_index'], 'track_id_SA'] = detections_sa['trajectory']\n",
    "all_fits.loc[detections_sa['detect_index'], 'D_av'] = detections_sa['D_av']\n",
    "\n",
    "all_fits['log10(D_av)'] = np.log10(all_fits['D_av'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 256)\n",
    "n_min = len(x[x<(lmin-vmin) / (vmax - vmin)])\n",
    "n_max = len(x[x>(lmax-vmin) / (vmax - vmin)])\n",
    "seg1 = np.array(n_min * [cmap(0.),])\n",
    "seg2 = cmap(np.linspace(0, 1, 256-n_min-n_max))\n",
    "seg3 = np.array(n_max * [cmap(1.),])\n",
    "colors = np.vstack((seg1, seg2, seg3))\n",
    "coolramp = mpl.colors.ListedColormap(\n",
    "    colors=np.vstack((seg1, seg2, seg3)), \n",
    "    N=256, \n",
    "    name='cool_sat'\n",
    "    )\n",
    "coolramp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot overall probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for holding figure handles\n",
    "all_figures = []\n",
    "\n",
    "# finding tick positions and labels\n",
    "logD_intervals = np.arange(np.log10(diff_coefs[0]), np.log10(diff_coefs[-1]) + 1)\n",
    "D_intervals = 10**logD_intervals\n",
    "xtick_labels = [f\"$\\\\mathdefault{{10^{{{Dint}}}}}$\" for Dint in logD_intervals.astype('int')]\n",
    "\n",
    "# initiate plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6.5, 4))\n",
    "\n",
    "cpo_max = 0\n",
    "norm = mpl.colors.LogNorm(vmin=diff_coefs[0], vmax=diff_coefs[-1])\n",
    "scalar_mappable = mpl.cm.ScalarMappable(norm=norm, cmap=coolramp)\n",
    "\n",
    "for icell in all_fits['roinum_unique'].unique():\n",
    "    \n",
    "    cell_fits = all_fits[all_fits['roinum_unique'] == icell]\n",
    "    cell_fits = cell_fits[~np.isnan(cell_fits['track_id_SA'])]\n",
    "    cell_track_posteriors = track_probabilities[:, cell_fits['track_id_SA'].unique().astype('int')]\n",
    "\n",
    "    cell_posterior_occs = (\n",
    "        cell_track_posteriors * cell_fits.groupby('track_id_SA')['track_id_SA'].count().values\n",
    "        ).sum(axis=1) / len(cell_fits)\n",
    "    \n",
    "    if cell_posterior_occs.max() > cpo_max: cpo_max = cell_posterior_occs.max()\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(left=diff_coefs[0], right=diff_coefs[-1])\n",
    "    \n",
    "    ax.plot(diff_coefs, \n",
    "            cell_posterior_occs,\n",
    "            color=minor_line_color,\n",
    "            lw=minor_line_width,\n",
    "            alpha=minor_line_alpha)\n",
    "\n",
    "ax.set_ylabel('Probability', fontsize=22)\n",
    "\n",
    "if ymax_overall_plot is None: ymax = 1.05 * cpo_max\n",
    "ax.set_ylim(bottom=0, top=ymax_overall_plot)\n",
    "\n",
    "ax.plot(diff_coefs, overall_probability, \n",
    "        color=major_line_color, lw=major_line_width)\n",
    "\n",
    "ax.tick_params(axis='x', labelbottom=False)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "cbar = plt.colorbar(\n",
    "    scalar_mappable,\n",
    "    orientation='horizontal',\n",
    "    ticks=D_intervals,\n",
    "    ax=ax,\n",
    "    label=r'$D_{app}\\ (\\mu m^2/s)$',\n",
    "    pad=0\n",
    "    )\n",
    "\n",
    "cbar.solids.set(alpha=1)\n",
    "cbar.ax.set_xticklabels(xtick_labels)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "cbar.set_label(r'$D_{app}\\ (\\mu m^2/s)$', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "all_figures.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "for imov in all_fits['movie_id'].unique():\n",
    "\n",
    "    # find overall probability for current movie\n",
    "    movie_fits = all_fits[all_fits['movie_id'] == imov]\n",
    "    movie_fits = movie_fits[~np.isnan(movie_fits['track_id_SA'])]\n",
    "    movie_track_probabilities = track_probabilities[:, movie_fits['track_id_SA'].unique().astype('int')]\n",
    "\n",
    "    movie_probability = (movie_track_probabilities * movie_fits.groupby('track_id_SA')['track_id_SA'].count().values).sum(axis=1) / len(movie_fits)\n",
    "\n",
    "    mask = all_masks[imov]\n",
    "    contours = bu.labels_to_contours(mask, level=0.5)\n",
    "    contours = [[bu.smooth_polygon(contour)] for contour in contours]\n",
    "\n",
    "    fig, ax = plt.subplots(2,1, figsize=(3.25, 6))\n",
    "    fig.suptitle(Path(fits_files[imov]).stem, fontsize=11, y=0.92)\n",
    "    ax[0].set_xscale('log')\n",
    "    ax[0].set_xlim(left=diff_coefs[0], right=diff_coefs[-1])\n",
    "\n",
    "    if ymax_movie_plot is None: ymax_movie_plot = movie_track_probabilities.max()*1.05\n",
    "    ax[0].set_ylim(bottom=0, top=ymax_movie_plot)\n",
    "\n",
    "    ax[0].plot(diff_coefs, movie_track_probabilities,\n",
    "               color=minor_line_color,\n",
    "               lw=minor_line_width,\n",
    "               alpha=minor_line_alpha)\n",
    "    ax[0].plot(diff_coefs, movie_probability,\n",
    "               color=major_line_color,\n",
    "               lw=major_line_width)\n",
    "    ax[0].set_ylabel('Probability', fontsize=11)\n",
    "\n",
    "    ax[0].tick_params(axis='x', labelbottom=False)\n",
    "    ax[0].tick_params(axis='y', labelsize=8)\n",
    "    \n",
    "    ax[1].imshow(np.zeros(mask.shape), cmap='binary_r')\n",
    "    bu.crop_to_labels(ax[1], mask)\n",
    "    ax[1].set_axis_off()\n",
    "    for contour in contours:\n",
    "        ax[1].plot(contour[0][:,1], contour[0][:,0], \n",
    "                   lw=roi_line_width, \n",
    "                   alpha=roi_line_alpha, \n",
    "                   color=roi_line_color)\n",
    "    scatmap = ax[1].scatter(\n",
    "        data=movie_fits.sort_values('D_av', ascending=False),\n",
    "        x='col',\n",
    "        y='row',\n",
    "        c='D_av',\n",
    "        edgecolor='none',\n",
    "        alpha=marker_alpha,\n",
    "        s=marker_size,\n",
    "        cmap=coolramp,\n",
    "        norm=norm\n",
    "        )\n",
    "    ax[0].set_xticks([])\n",
    "    cbar = plt.colorbar(\n",
    "        scatmap,\n",
    "        orientation='horizontal',\n",
    "        ticks=D_intervals,\n",
    "        ax=ax[0],\n",
    "        label=r'$D_{app}\\ (\\mu m^2/s)$',\n",
    "        pad=0\n",
    "        )\n",
    "    \n",
    "    cbar.solids.set(alpha=1)\n",
    "    cbar.ax.set_xticklabels(xtick_labels)\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "    cbar.set_label(r'$D_{app}\\ (\\mu m^2/s)$', fontsize=11)\n",
    "    \n",
    "    scalebar = sb.ScaleBar(**default_scalebar_props)\n",
    "    ax[1].add_artist(scalebar)\n",
    "        \n",
    "    all_figures.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output folder if it doesn't already exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# create DataFrame for storing \n",
    "output_df = pd.DataFrame(\n",
    "    data = {\n",
    "        'diff_coefs': diff_coefs,\n",
    "        'overall': overall_probability,\n",
    "    }\n",
    ")\n",
    "\n",
    "# re-calculating for each cell/roi\n",
    "for icell in all_fits['roinum_unique'].unique():\n",
    "    cell_fits = all_fits[all_fits['roinum_unique'] == icell]\n",
    "    cell_fits = cell_fits[~np.isnan(cell_fits['track_id_SA'])]\n",
    "    cell_track_posteriors = track_probabilities[:, cell_fits['track_id_SA'].unique().astype('int')]\n",
    "    cell_posterior_occs = (\n",
    "        cell_track_posteriors * cell_fits.groupby('track_id_SA')['track_id_SA'].count().values\n",
    "        ).sum(axis=1) / len(cell_fits)\n",
    "    output_df[f'roi{int(icell):03}'] = cell_posterior_occs\n",
    "\n",
    "output_df.to_csv(\n",
    "    join(output_folder, probabilities_csv_fname)\n",
    ")\n",
    "\n",
    "# saving figures to single pdf\n",
    "image_pdf = PdfPages(join(output_folder, figures_pdf_fname))\n",
    "for fig in all_figures:\n",
    "    image_pdf.savefig(fig, bbox_inches='tight')\n",
    "image_pdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saspt-dan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
